{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janitrasatria/miniforge3/envs/llm-rag-langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import uuid\n",
    "import re\n",
    "import redis\n",
    "import json\n",
    "import hashlib\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from pprint import pprint\n",
    "from typing import List, Any\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "import plotly.graph_objects as go\n",
    "from pydantic import BaseModel, Field  \n",
    "from langchain.tools import tool  \n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_EMBEDDINGS_MODEL = \"text-embedding-3-large\"\n",
    "OLLAMA_MODEL = \"adijayainc/bhsa-llama3.2\"\n",
    "OLLAMA_EMBEDDINGS_MODEL = \"snowflake-arctic-embed2\"\n",
    "CHROMA_PATH = \"./chroma_langchain_db\"\n",
    "CHROMA_COLLECTION = \"juragan_klod_collection\"\n",
    "API_URL = \"http://localhost:5050\"\n",
    "QUESTION_THRESHOLD = 0.90\n",
    "WITH_OLLAMA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe LLM Model & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMModel:\n",
    "    @staticmethod\n",
    "    def llm():\n",
    "        if not WITH_OLLAMA:\n",
    "            return ChatOpenAI(model=OPENAI_MODEL, temperature=0.5, max_tokens=500)\n",
    "        \n",
    "        return ChatOllama(model=OLLAMA_MODEL, temperature=0.5, max_tokens=500)\n",
    "\n",
    "    @staticmethod\n",
    "    def embeddings():\n",
    "        if not WITH_OLLAMA:\n",
    "            return OpenAIEmbeddings(model=OPENAI_EMBEDDINGS_MODEL)\n",
    "\n",
    "        return OllamaEmbeddings(model=OLLAMA_EMBEDDINGS_MODEL)\n",
    "    \n",
    "    @staticmethod\n",
    "    def bind_tools(llm, tools):\n",
    "        setattr(llm, 'tools', tools)\n",
    "        return llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk RAG Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDocument:\n",
    "    def __init__(self):\n",
    "        self.new_documents = []\n",
    "\n",
    "    def load_documents(self) -> List[Document]:\n",
    "        loader = DirectoryLoader(DATA_PATH, glob=\"*.txt\")\n",
    "        documents = loader.load()\n",
    "        return documents\n",
    "\n",
    "    def split_by_subtopics(self, text: str) -> List[str]:\n",
    "        subtopic_pattern = r\"\\[T\\](.*?)\\[/T\\]\"\n",
    "        subtopics = re.findall(subtopic_pattern, text, re.DOTALL)\n",
    "        return subtopics\n",
    "\n",
    "    def split_by_content(self, text: str) -> List[str]:\n",
    "        content_pattern = r\"\\[PC\\](.*?)\\[/PC\\]\"\n",
    "        content = re.findall(content_pattern, text, re.DOTALL)\n",
    "        return content\n",
    "\n",
    "    def format_list_items(self, content: str) -> str:\n",
    "        list_item_pattern = r\"(^|\\n)- (.*?)(?=\\n|$)\"\n",
    "        formatted_content = re.sub(r\"(-\\s.*?)(?=\\s*-|\\n|$)\", r\"\\n\\1\", content).strip()\n",
    "        return formatted_content\n",
    "\n",
    "    def chunk_documents_by_subtopic(self, documents: List[Document]) -> List[Document]:\n",
    "        self.new_documents = []\n",
    "\n",
    "        for doc in documents:\n",
    "            metadata = doc.metadata\n",
    "            page_content = doc.page_content\n",
    "\n",
    "            subtopics = self.split_by_subtopics(page_content)\n",
    "            content_blocks = self.split_by_content(page_content)\n",
    "            formatted_content = [self.format_list_items(content) for content in content_blocks]\n",
    "\n",
    "            for subtopic, content in zip(subtopics, formatted_content):\n",
    "                parts = subtopic.split(\"\\n\", 1)\n",
    "                topic = parts[0].strip()\n",
    "\n",
    "                new_metadata = metadata.copy()\n",
    "                new_metadata[\"topic\"] = topic\n",
    "\n",
    "                self.new_documents.append(\n",
    "                    Document(page_content=f\"{topic}\\n{content}\", metadata=new_metadata)\n",
    "                )\n",
    "\n",
    "        return self.new_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Document Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:langchain_community.document_loaders.directory:Processing file: ../data/kubernetes.txt\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): packages.unstructured.io:443\n",
      "DEBUG:urllib3.connectionpool:https://packages.unstructured.io:443 \"GET /python-telemetry?version=0.16.17&platform=Darwin&python3.11&arch=arm64&gpu=False&dev=false HTTP/1.1\" 302 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): unstructured.io:443\n",
      "DEBUG:urllib3.connectionpool:https://unstructured.io:443 \"GET /?version=0.16.17&platform=Darwin&python3.11&arch=arm64&gpu=False&dev=false HTTP/1.1\" 200 232869\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): packages2.unstructured.io:443\n",
      "DEBUG:urllib3.connectionpool:https://packages2.unstructured.io:443 \"GET /python-telemetry?version=0.16.17&platform=Darwin&python3.11&arch=arm64&gpu=False&dev=false HTTP/1.1\" 200 599\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Layanan Cloud Kubernetes[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TLayanan Cloud KubernetesT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Spesifikasi Infrastruktur Cloud Kubernetes[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TSpesifikasi Infrastruktur Cloud KubernetesT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Fitur Utama Cloud Kubernetes[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TFitur Utama Cloud KubernetesT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DEBUG:langchain_community.document_loaders.directory:Processing file: ../data/about-us.txt\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DEBUG:langchain_community.document_loaders.directory:Processing file: ../data/vps.txt\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Layanan Cloud VPS[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TLayanan Cloud VPST\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Spesifikasi Server Cloud VPS[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TSpesifikasi Server Cloud VPST\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Fitur Utama Cloud VPS[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TFitur Utama Cloud VPST\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DEBUG:langchain_community.document_loaders.directory:Processing file: ../data/serverless.txt\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Layanan Cloud Serverless[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TLayanan Cloud ServerlessT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Spesifikasi Infrastruktur Cloud Serverless[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TSpesifikasi Infrastruktur Cloud ServerlessT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Fitur Utama Cloud Serverless[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TFitur Utama Cloud ServerlessT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DEBUG:langchain_community.document_loaders.directory:Processing file: ../data/storage.txt\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Layanan Cloud Storage[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TLayanan Cloud StorageT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Spesifikasi Penyimpanan Cloud Storage[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TSpesifikasi Penyimpanan Cloud StorageT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[T]Fitur Utama Cloud Storage[/T]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 5 word tokens, it will not count toward sentence count.\n",
      "TFitur Utama Cloud StorageT\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[PC]\n",
      "DETAIL:unstructured.trace:Sentence does not exceed 3 word tokens, it will not count toward sentence count.\n",
      "PC\n",
      "DETAIL:unstructured.trace:Not narrative. Text exceeds cap ratio 0.5:\n",
      "\n",
      "[/PC]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/kubernetes.txt', 'topic': 'Layanan Cloud Kubernetes'}, page_content='Layanan Cloud Kubernetes\\nJuraganKlod Kubernetes adalah platform manajemen kontainer yang memungkinkan pengelolaan aplikasi berbasis kontainer dengan efisien. Dengan infrastruktur yang kuat, termasuk node worker dengan prosesor Intel Xeon Silver 4210 dan RAM hingga 256 GB, JuraganKlod Kubernetes mendukung orkestrasi kontainer yang otomatis dan skalabilitas yang mudah. Fitur integrasi CI/CD memungkinkan pengembangan yang lebih cepat, sementara dukungan multi-cloud memberikan fleksibilitas dalam pengelolaan infrastruktur.\\n\\nPlatform ini juga dilengkapi dengan jaringan internal 10 Gbps untuk komunikasi antar node yang cepat, serta penyimpanan terdistribusi menggunakan Ceph atau GlusterFS. Dengan kemampuan auto-scaling, JuraganKlod Kubernetes secara otomatis menyesuaikan jumlah kontainer berdasarkan beban kerja, memastikan aplikasi Anda selalu tersedia dan responsif terhadap permintaan pasar.\\n\\nJuraganKlod Kubernetes sangat cocok untuk microservices, memungkinkan pengembangan dan pengelolaan aplikasi mikroservis dengan cepat dan mudah.'),\n",
      " Document(metadata={'source': '../data/kubernetes.txt', 'topic': 'Spesifikasi Infrastruktur Cloud Kubernetes'}, page_content='Spesifikasi Infrastruktur Cloud Kubernetes\\nNode Worker: Server dengan Intel Xeon Silver 4210 (10 core, 2.2 GHz) atau AMD EPYC 7302 (16 core, 3.0 GHz) untuk mendukung beban kerja yang tinggi.\\n\\nRAM: Minimum 16 GB DDR4 untuk setiap node, dengan opsi hingga 256 GB untuk aplikasi yang lebih besar.\\n\\nPenyimpanan: Penyimpanan terdistribusi menggunakan Ceph atau GlusterFS, dengan SSD NVMe untuk kecepatan akses data yang tinggi.\\n\\nJaringan: Jaringan internal 10 Gbps untuk komunikasi antar node yang cepat dan efisien.'),\n",
      " Document(metadata={'source': '../data/kubernetes.txt', 'topic': 'Fitur Utama Cloud Kubernetes'}, page_content='Fitur Utama Cloud Kubernetes\\nOrkestrasi Kontainer: Mengelola siklus hidup aplikasi kontainer dengan mudah, termasuk penyebaran, penskalaan, dan pemantauan.\\n\\nIntegrasi CI/CD: Mendukung integrasi dengan alat Continuous Integration dan Continuous Deployment seperti Jenkins, GitLab CI, dan CircleCI.\\n\\nMulti-Cloud Support: Dapat dioperasikan di berbagai penyedia cloud, memberikan fleksibilitas dalam pengelolaan infrastruktur.\\n\\nAuto-Scaling: Secara otomatis menyesuaikan jumlah kontainer berdasarkan beban kerja, memastikan ketersediaan aplikasi.'),\n",
      " Document(metadata={'source': '../data/about-us.txt', 'topic': 'Tentang JuraganKlod'}, page_content='Tentang JuraganKlod\\nJuraganKlod adalah penyedia layanan cloud terkemuka yang menawarkan berbagai solusi komputasi awan untuk memenuhi kebutuhan bisnis modern. Kami menyediakan layanan VPS (Virtual Private Server), Kubernetes, Serverless, dan Cloud Storage yang dirancang untuk memberikan performa tinggi, skalabilitas, dan keamanan yang optimal.'),\n",
      " Document(metadata={'source': '../data/about-us.txt', 'topic': 'Mengapa Memilih JuraganKlod'}, page_content='Mengapa Memilih JuraganKlod\\n- Performa Tinggi: Layanan kami dirancang dengan spesifikasi canggih untuk memastikan performa optimal. \\n- Keamanan: Kami menyediakan fitur keamanan tingkat tinggi seperti firewall canggih, perlindungan DDoS, dan enkripsi data. \\n- Skalabilitas: Layanan kami mendukung skalabilitas otomatis untuk menyesuaikan dengan kebutuhan bisnis Anda. \\n- Fleksibilitas: Dukungan multi-cloud dan berbagai bahasa pemrograman memungkinkan fleksibilitas dalam pengembangan dan pengelolaan aplikasi. \\n- Efisiensi Biaya: Model pembayaran berdasarkan penggunaan memastikan Anda hanya membayar untuk sumber daya yang digunakan.'),\n",
      " Document(metadata={'source': '../data/about-us.txt', 'topic': 'Visi dan Misi JuraganKlod'}, page_content='Visi dan Misi JuraganKlod\\n- Visi: Menjadi penyedia layanan cloud terkemuka yang mendukung transformasi digital bisnis di seluruh dunia. \\n- Misi: Menyediakan solusi cloud yang inovatif, aman, dan efisien untuk membantu bisnis mencapai efisiensi operasional dan pertumbuhan yang berkelanjutan.'),\n",
      " Document(metadata={'source': '../data/about-us.txt', 'topic': 'CEO JuraganKlod'}, page_content='CEO JuraganKlod\\nUjang Sutrisna adalah CEO dan pendiri JuraganKlod. Dengan pengalaman lebih dari 20 tahun di industri teknologi informasi, Ujang telah memimpin berbagai proyek transformasi digital di perusahaan-perusahaan besar. Sebelum mendirikan JuraganKlod, Ujang bekerja di beberapa perusahaan teknologi terkemuka, termasuk Google dan Amazon, di mana ia mengembangkan keahliannya dalam manajemen infrastruktur cloud dan pengembangan aplikasi berbasis cloud.'),\n",
      " Document(metadata={'source': '../data/about-us.txt', 'topic': 'Biografi Ujang Sutrisna'}, page_content='Biografi Ujang Sutrisna\\nUjang Sutrisna lahir dan dibesarkan di Bandung, Indonesia. Ia menyelesaikan pendidikan sarjana di bidang Teknik Informatika dari Institut Teknologi Bandung (ITB) dan melanjutkan studi magister di bidang Manajemen Teknologi di Massachusetts Institute of Technology (MIT). Ujang memulai karirnya sebagai insinyur perangkat lunak di Google, di mana ia berkontribusi pada pengembangan berbagai produk cloud. Setelah itu, ia bergabung dengan Amazon Web Services (AWS) sebagai manajer produk, di mana ia memimpin tim yang mengembangkan layanan cloud inovatif. Dengan visi untuk membawa teknologi cloud ke lebih banyak bisnis di Indonesia dan Asia Tenggara, Ujang mendirikan JuraganKlod pada tahun 2015. Di bawah kepemimpinannya, JuraganKlod telah berkembang pesat dan menjadi salah satu penyedia layanan cloud terkemuka di kawasan ini. Ujang dikenal sebagai pemimpin yang visioner dan inovatif, dengan komitmen kuat untuk mendukung transformasi digital bisnis melalui solusi cloud yang efisien dan aman.'),\n",
      " Document(metadata={'source': '../data/about-us.txt', 'topic': 'Alamat JuraganKlod'}, page_content='Alamat JuraganKlod\\nJl. Kepastian yang tak berujung pasti, Kabupaten Gaib Selatan No. 30, Telp: +6221-123-456'),\n",
      " Document(metadata={'source': '../data/vps.txt', 'topic': 'Layanan Cloud VPS'}, page_content='Layanan Cloud VPS\\nJuraganKlod VPS adalah solusi hosting yang memberikan kontrol penuh dan performa tinggi melalui server virtual pribadi. Dengan spesifikasi canggih seperti prosesor Intel Xeon Gold 6248R atau AMD EPYC 7742, RAM hingga 128 GB DDR4 ECC, dan penyimpanan SSD NVMe yang cepat, JuraganKlod VPS dirancang untuk memenuhi kebutuhan aplikasi bisnis modern. Setiap VPS dilengkapi dengan firewall canggih, perlindungan DDoS, dan backup otomatis harian, memastikan keamanan dan keandalan data Anda.\\n\\nDengan akses root penuh, pengguna dapat menginstal perangkat lunak dan mengonfigurasi server sesuai kebutuhan. JuraganKlod VPS juga menawarkan bandwidth tidak terbatas dengan koneksi internet 1 Gbps, menjadikannya pilihan ideal untuk hosting situs web, aplikasi web, dan pengembangan perangkat lunak. Fleksibilitas dalam penyesuaian sumber daya memungkinkan Anda untuk mengoptimalkan biaya dan performa sesuai dengan pertumbuhan bisnis Anda.'),\n",
      " Document(metadata={'source': '../data/vps.txt', 'topic': 'Spesifikasi Server Cloud VPS'}, page_content='Spesifikasi Server Cloud VPS\\nProsesor: Intel Xeon Gold 6248R (24 core, 3.0 GHz) atau AMD EPYC 7742 (64 core, 2.25 GHz) untuk performa komputasi yang optimal.\\n\\nRAM: Pilihan mulai dari 2 GB hingga 128 GB DDR4 ECC, memungkinkan penyesuaian sesuai kebutuhan aplikasi.\\n\\nPenyimpanan: SSD NVMe dengan kecepatan baca/tulis hingga 3.500/3.000 MB/s, tersedia dalam kapasitas mulai dari 50 GB hingga 2 TB.\\n\\nBandwidth: Koneksi internet 1 Gbps dengan bandwidth tidak terbatas, memastikan kecepatan akses yang tinggi.'),\n",
      " Document(metadata={'source': '../data/vps.txt', 'topic': 'Fitur Utama Cloud VPS'}, page_content='Fitur Utama Cloud VPS\\nSumber Daya Terisolasi: Setiap VPS memiliki sumber daya CPU, RAM, dan penyimpanan yang terpisah, memastikan kinerja optimal tanpa gangguan dari pengguna lain.\\n\\nKeamanan Tinggi: Dilengkapi dengan firewall canggih, perlindungan DDoS, dan backup otomatis harian untuk melindungi data Anda.\\n\\nAkses Root Penuh: Kontrol penuh atas server Anda dengan akses root, memungkinkan instalasi perangkat lunak dan konfigurasi sesuai keinginan.\\n\\nPanel Kontrol Intuitif: Mengelola VPS Anda dengan mudah melalui panel kontrol berbasis web yang user-friendly.'),\n",
      " Document(metadata={'source': '../data/serverless.txt', 'topic': 'Layanan Cloud Serverless'}, page_content='Layanan Cloud Serverless\\nJuraganKlod Serverless adalah platform komputasi yang memungkinkan Anda menjalankan aplikasi tanpa perlu mengelola server, memberikan kemudahan dan efisiensi dalam pengembangan. Dengan spesifikasi infrastruktur yang canggih, termasuk prosesor Intel Xeon Scalable dan RAM yang dapat disesuaikan, JuraganKlod Serverless menawarkan skalabilitas otomatis berdasarkan permintaan aplikasi. Model pembayaran berdasarkan penggunaan memastikan Anda hanya membayar untuk sumber daya yang digunakan, mengurangi biaya operasional.\\n\\nPlatform ini mendukung berbagai bahasa pemrograman dan framework, seperti Node.js, Python, dan Java, sehingga memudahkan pengembang dalam membangun dan meluncurkan aplikasi. Dengan koneksi internet 1 Gbps, JuraganKlod Serverless menjamin waktu respons yang cepat, memungkinkan Anda untuk fokus pada pengembangan aplikasi tanpa khawatir tentang manajemen infrastruktur.'),\n",
      " Document(metadata={'source': '../data/serverless.txt', 'topic': 'Spesifikasi Infrastruktur Cloud Serverless'}, page_content='Spesifikasi Infrastruktur Cloud Serverless\\nProsesor: Intel Xeon Scalable atau AMD EPYC untuk mendukung eksekusi fungsi dengan latensi rendah.\\n\\nRAM: Opsi mulai dari 128 MB hingga 16 GB per fungsi, memungkinkan penyesuaian sesuai kebutuhan aplikasi.\\n\\nPenyimpanan: Penyimpanan sementara untuk fungsi yang berjalan, dengan akses cepat ke penyimpanan cloud untuk data permanen.\\n\\nJaringan: Koneksi internet 1 Gbps untuk eksekusi fungsi yang cepat dan responsif.'),\n",
      " Document(metadata={'source': '../data/serverless.txt', 'topic': 'Fitur Utama Cloud Serverless'}, page_content='Fitur Utama Cloud Serverless\\nTanpa Manajemen Server: Fokus pada pengembangan aplikasi tanpa perlu khawatir tentang infrastruktur.\\n\\nSkalabilitas Otomatis: Secara otomatis menyesuaikan kapasitas berdasarkan permintaan aplikasi, dengan waktu respons yang cepat.\\n\\nIntegrasi Mudah: Mendukung berbagai bahasa pemrograman dan framework, termasuk Node.js, Python, Java, dan Go.\\n\\nPembayaran Berdasarkan Penggunaan: Hanya membayar untuk waktu eksekusi dan sumber daya yang digunakan, mengurangi biaya operasional.'),\n",
      " Document(metadata={'source': '../data/storage.txt', 'topic': 'Layanan Cloud Storage'}, page_content='Layanan Cloud Storage\\nJuraganKlod Cloud Storage adalah solusi penyimpanan data yang aman dan scalable, dirancang untuk menyimpan dan mengelola data Anda dengan mudah. Dengan dukungan untuk penyimpanan objek dan blok, serta kecepatan akses tinggi menggunakan SSD NVMe, JuraganKlod Cloud Storage memastikan data Anda selalu tersedia dan dapat diakses kapan saja. Fitur replikasi data otomatis di beberapa lokasi menjamin ketahanan dan ketersediaan data, sementara enkripsi AES-256 melindungi data Anda dari ancaman keamanan.\\n\\nSelain itu, JuraganKlod Cloud Storage menawarkan integrasi API yang kuat, memungkinkan Anda untuk menghubungkan layanan penyimpanan dengan aplikasi lain dengan mudah. Fitur backup otomatis dan pemulihan bencana memberikan perlindungan tambahan terhadap kehilangan data, sementara alat analitik penyimpanan membantu Anda memantau penggunaan dan mengoptimalkan biaya penyimpanan sesuai kebutuhan bisnis Anda.'),\n",
      " Document(metadata={'source': '../data/storage.txt', 'topic': 'Spesifikasi Penyimpanan Cloud Storage'}, page_content='Spesifikasi Penyimpanan Cloud Storage\\nTipe Penyimpanan: Penyimpanan objek dengan dukungan untuk S3 API, serta penyimpanan blok untuk aplikasi yang memerlukan akses cepat.\\n\\nKecepatan Akses: SSD NVMe dengan kecepatan baca/tulis hingga 3.500/3.000 MB/s untuk penyimpanan objek.\\n\\nReplikasi Data: Replikasi data otomatis di beberapa lokasi untuk memastikan ketersediaan dan ketahanan data.\\n\\nKeamanan: Enkripsi AES-256 untuk data yang disimpan dan saat transit, serta kontrol akses berbasis peran (RBAC).'),\n",
      " Document(metadata={'source': '../data/storage.txt', 'topic': 'Fitur Utama Cloud Storage'}, page_content='Fitur Utama Cloud Storage\\nPenyimpanan yang Fleksibel: Pilihan penyimpanan yang dapat disesuaikan dengan kebutuhan, mulai dari penyimpanan objek hingga penyimpanan blok.\\n\\nBackup dan Pemulihan: Fitur backup otomatis dan pemulihan bencana untuk melindungi data Anda dari kehilangan.\\n\\nIntegrasi API: Mudah diintegrasikan dengan aplikasi dan layanan lain melalui API yang kuat.\\n\\nAnalitik Penyimpanan: Alat analitik untuk memantau penggunaan penyimpanan dan mengoptimalkan biaya.')]\n"
     ]
    }
   ],
   "source": [
    "vector_document = VectorDocument()\n",
    "new_doc = vector_document.chunk_documents_by_subtopic(vector_document.load_documents())\n",
    "\n",
    "pprint(new_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreDocuments:\n",
    "    def __init__(self):\n",
    "        self.vectorstore = None\n",
    "\n",
    "    def vector_store(self) -> 'VectorStoreDocuments':\n",
    "        self.vectorstore = Chroma(\n",
    "            collection_name=CHROMA_COLLECTION,\n",
    "            embedding_function=LLMModel.embeddings(),\n",
    "            persist_directory=CHROMA_PATH,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def store_documents(self, documents: List[Document]) -> None:\n",
    "        self.vectorstore.add_documents(documents=documents, overwrite=True)\n",
    "\n",
    "    def retriever(self) -> VectorStoreRetriever:\n",
    "        return self.vectorstore.as_retriever()\n",
    "    \n",
    "    def remove_collection(self):\n",
    "        self.vectorstore.reset_collection()\n",
    "\n",
    "    def search(self, query: str, k: int = 5) -> List[Document]:\n",
    "        return self.vectorstore.similarity_search(query=query, k=k)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Document Chunk to VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "DEBUG:chromadb.config:Starting component System\n",
      "DEBUG:chromadb.config:Starting component Posthog\n",
      "DEBUG:chromadb.config:Starting component OpenTelemetryClient\n",
      "DEBUG:chromadb.config:Starting component SqliteDB\n",
      "DEBUG:chromadb.config:Starting component SimpleQuotaEnforcer\n",
      "DEBUG:chromadb.config:Starting component SimpleRateLimitEnforcer\n",
      "DEBUG:chromadb.config:Starting component LocalSegmentManager\n",
      "DEBUG:chromadb.config:Starting component LocalExecutor\n",
      "DEBUG:chromadb.config:Starting component SegmentAPI\n",
      "DEBUG:chromadb.api.segment:Collection juragan_klod_collection already exists, returning existing collection.\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x3194c3b50>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): us.i.posthog.com:443\n",
      "DEBUG:urllib3.connectionpool:https://us.i.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 15\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 29 Jan 2025 20:35:01 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:chromadb.config:Starting component PersistentLocalHnswSegment\n"
     ]
    }
   ],
   "source": [
    "store = VectorStoreDocuments()\n",
    "vs = store.vector_store()\n",
    "vs.remove_collection()\n",
    "vs.store_documents(new_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 29 Jan 2025 20:35:01 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='ae1640e7-5f17-4fe8-bfb3-c727ed5793ce', metadata={'source': '../data/kubernetes.txt', 'topic': 'Layanan Cloud Kubernetes'}, page_content='Layanan Cloud Kubernetes\\nJuraganKlod Kubernetes adalah platform manajemen kontainer yang memungkinkan pengelolaan aplikasi berbasis kontainer dengan efisien. Dengan infrastruktur yang kuat, termasuk node worker dengan prosesor Intel Xeon Silver 4210 dan RAM hingga 256 GB, JuraganKlod Kubernetes mendukung orkestrasi kontainer yang otomatis dan skalabilitas yang mudah. Fitur integrasi CI/CD memungkinkan pengembangan yang lebih cepat, sementara dukungan multi-cloud memberikan fleksibilitas dalam pengelolaan infrastruktur.\\n\\nPlatform ini juga dilengkapi dengan jaringan internal 10 Gbps untuk komunikasi antar node yang cepat, serta penyimpanan terdistribusi menggunakan Ceph atau GlusterFS. Dengan kemampuan auto-scaling, JuraganKlod Kubernetes secara otomatis menyesuaikan jumlah kontainer berdasarkan beban kerja, memastikan aplikasi Anda selalu tersedia dan responsif terhadap permintaan pasar.\\n\\nJuraganKlod Kubernetes sangat cocok untuk microservices, memungkinkan pengembangan dan pengelolaan aplikasi mikroservis dengan cepat dan mudah.'),\n",
      " Document(id='a893545b-24f4-4ca9-95a9-c5fdfd574fd5', metadata={'source': '../data/kubernetes.txt', 'topic': 'Fitur Utama Cloud Kubernetes'}, page_content='Fitur Utama Cloud Kubernetes\\nOrkestrasi Kontainer: Mengelola siklus hidup aplikasi kontainer dengan mudah, termasuk penyebaran, penskalaan, dan pemantauan.\\n\\nIntegrasi CI/CD: Mendukung integrasi dengan alat Continuous Integration dan Continuous Deployment seperti Jenkins, GitLab CI, dan CircleCI.\\n\\nMulti-Cloud Support: Dapat dioperasikan di berbagai penyedia cloud, memberikan fleksibilitas dalam pengelolaan infrastruktur.\\n\\nAuto-Scaling: Secara otomatis menyesuaikan jumlah kontainer berdasarkan beban kerja, memastikan ketersediaan aplikasi.'),\n",
      " Document(id='fa4bb887-0f0c-489e-8051-8b28ec4c77af', metadata={'source': '../data/kubernetes.txt', 'topic': 'Spesifikasi Infrastruktur Cloud Kubernetes'}, page_content='Spesifikasi Infrastruktur Cloud Kubernetes\\nNode Worker: Server dengan Intel Xeon Silver 4210 (10 core, 2.2 GHz) atau AMD EPYC 7302 (16 core, 3.0 GHz) untuk mendukung beban kerja yang tinggi.\\n\\nRAM: Minimum 16 GB DDR4 untuk setiap node, dengan opsi hingga 256 GB untuk aplikasi yang lebih besar.\\n\\nPenyimpanan: Penyimpanan terdistribusi menggunakan Ceph atau GlusterFS, dengan SSD NVMe untuk kecepatan akses data yang tinggi.\\n\\nJaringan: Jaringan internal 10 Gbps untuk komunikasi antar node yang cepat dan efisien.'),\n",
      " Document(id='a31020a7-e03a-4b88-a246-8edf1ffcfc67', metadata={'source': '../data/about-us.txt', 'topic': 'Tentang JuraganKlod'}, page_content='Tentang JuraganKlod\\nJuraganKlod adalah penyedia layanan cloud terkemuka yang menawarkan berbagai solusi komputasi awan untuk memenuhi kebutuhan bisnis modern. Kami menyediakan layanan VPS (Virtual Private Server), Kubernetes, Serverless, dan Cloud Storage yang dirancang untuk memberikan performa tinggi, skalabilitas, dan keamanan yang optimal.'),\n",
      " Document(id='d6fe0394-fc1d-46a8-9842-38b1030ecc77', metadata={'source': '../data/about-us.txt', 'topic': 'Mengapa Memilih JuraganKlod'}, page_content='Mengapa Memilih JuraganKlod\\n- Performa Tinggi: Layanan kami dirancang dengan spesifikasi canggih untuk memastikan performa optimal. \\n- Keamanan: Kami menyediakan fitur keamanan tingkat tinggi seperti firewall canggih, perlindungan DDoS, dan enkripsi data. \\n- Skalabilitas: Layanan kami mendukung skalabilitas otomatis untuk menyesuaikan dengan kebutuhan bisnis Anda. \\n- Fleksibilitas: Dukungan multi-cloud dan berbagai bahasa pemrograman memungkinkan fleksibilitas dalam pengembangan dan pengelolaan aplikasi. \\n- Efisiensi Biaya: Model pembayaran berdasarkan penggunaan memastikan Anda hanya membayar untuk sumber daya yang digunakan.')]\n"
     ]
    }
   ],
   "source": [
    "dd = vs.search(\"Saya pengen tau produk kubernetes?\", k=5)\n",
    "pprint(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_create_order(order_data: Any) -> (Any | dict[str, Any]):\n",
    "    response = requests.post(f\"{API_URL}/orders\", json=order_data)\n",
    "    return response.json() if response.status_code < 400 else {\"error\": response.json()}\n",
    "\n",
    "def api_get_list_product() -> (Any | dict[str, Any]):\n",
    "    response = requests.get(f\"{API_URL}/products\")\n",
    "    return response.json()\n",
    "\n",
    "def api_search_product(query: str) -> (Any | dict[str, Any]):\n",
    "    response = requests.get(f\"{API_URL}/products/?query={query}\")\n",
    "    return response.json()\n",
    "\n",
    "def api_check_order(order_number: str) -> (Any | dict[str, Any]):\n",
    "    response = requests.get(f\"{API_URL}/orders/{order_number}\")\n",
    "    return response.json() if response.status_code < 400 else {\"error\": response.json()}\n",
    "\n",
    "def api_report_order(year: str) -> (Any | dict[str, Any]):\n",
    "    response = requests.get(f\"{API_URL}/order-report?year={year}\")\n",
    "    return response.json() if response.status_code < 400 else {\"error\": response.json()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe LLM Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"get-list-product-tool\")\n",
    "def get_list_products():\n",
    "    \"\"\" Daftar produk dan harga yang tersedia, jelaskan jika ada yang bertanya spesifik tentang harga produk atau layanan yang tersedia. \"\"\"\n",
    "    response = api_get_list_product()\n",
    "    return response\n",
    "\n",
    "class GetProductRequest(BaseModel):\n",
    "    search: str = Field(description=\"Kata kunci untuk mencari produk atau layanan, bisa berupa nama produk atau SKU, jika pengguna belum mengetahui SKU, maka tanyakan terlebih dahulu dan berikan daftar produk\")\n",
    "\n",
    "@tool(\"get-product-tool\", args_schema=GetProductRequest)\n",
    "def get_product(search):\n",
    "    \"\"\" Mendapatkan informasi daftar harga dari layanan atau produk, hasil harus menampilkan SKU, Nama dan Harga, dalam hal ini produk bisa di sebut juga sebagai layanan\"\"\"\n",
    "    response = api_search_product(search)\n",
    "    product_text = \"\\n\".join(f\"SKU: {prod['sku']}, Nama: {prod['name']}, Harga: {prod['price']}\" for prod in response)\n",
    "    return product_text\n",
    "\n",
    "class GetOrderRequest(BaseModel):\n",
    "    sku: str = Field(description=\"SKU harus diisi, SKU adalah kode unik untuk produk, SKU bisa dilihat di daftar produk, jika pengguna belum mengetahui SKU, maka tanyakan terlebih dahulu dan berikan daftar produk, jika customer memberikan nama produk, maka lihat nama produk tersebut di daftar produk untuk mendapatkan SKU\")\n",
    "    email: str = Field(description=\"Email customer harus diisi, jika customer belum menyebutkan email, maka tanyakan terlebih dahulu\")\n",
    "    full_name: str = Field(description=\"Nama lengkap customer, jika customer belum menyebutkan nama, maka tanyakan terlebih dahulu\")\n",
    "\n",
    "@tool(\"create-order-tool\", args_schema=GetOrderRequest)\n",
    "def create_order(sku, email, full_name):\n",
    "    \"\"\" Membuat order baru, hasil harus menampilkan nomor order dan link pembayaran, jika ada error maka tampilkan pesan terkait error tersebut, jika customer telah menyebutkan nama, maka gunakan nama tersebut untuk mengisi data order, jika pengguna belum menyebutkan email atau nama, maka tanya terlebih dahulu emailnya\"\"\"\n",
    "    response = api_create_order({\"sku\": sku, \"email\": email, \"full_name\": full_name})\n",
    "    if \"error\" in response:\n",
    "        return f\"Error: {response['error']}, try again\"\n",
    "    return f\"Order Number: {response['order_number']} created. Payment link: {response['invoice_url']}\"\n",
    "\n",
    "class GetCheckOrderRequest(BaseModel):\n",
    "    order_number: str = Field(description=\"Nomor order harus diisi, nomor order bisa dilihat di invoice yang diberikan saat pembuatan order\")\n",
    "\n",
    "@tool(\"check-order-tool\", args_schema=GetCheckOrderRequest)\n",
    "def check_order(order_number):\n",
    "    \"\"\" Memeriksa order berdasarkan nomor order, cek berdasarkan payment_status, jika order telah selesai maka tampilkan status selesai, jika order belum selesai maka tampilkan status pending, jika order tidak ditemukan maka tampilkan pesan order tidak ditemukan, Jika customer sudah merasa membayar namun status masih pending, maka berikan nomor telepon JuraganKlod untuk konfirmasi pembayaran\"\"\"\n",
    "    response = api_check_order(order_number)\n",
    "    if \"error\" in response:\n",
    "        return f\"Error: {response['error']}, try again\"\n",
    "\n",
    "    status = response['payment_status']\n",
    "    if status == \"pending\":\n",
    "        return f\"Status: {status}. Please complete payment soon.\"\n",
    "    return f\"Status: {status}. Thank you for your payment.\"\n",
    "\n",
    "class OrderReportRequest(BaseModel):\n",
    "    year: int = Field(description=\"Tahun laporan order harus diisi, laporan order berdasarkan tahun\")\n",
    "\n",
    "@tool(\"order-report-tool\", args_schema=OrderReportRequest)\n",
    "def order_report(year: int):\n",
    "    \"\"\"Membuat grafik laporan order per tahun, hasil berisi grafik bar chart yang menampilkan jumlah order per bulan, hasilnya adalah markdown image\"\"\"\n",
    "    response = api_report_order(year)\n",
    "    if \"error\" in response:\n",
    "        return f\"Error: {response['error']}, try again\"\n",
    "\n",
    "    months = response['months']\n",
    "    order_counts = response['order_counts']\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(x=months, y=order_counts, marker_color='blue')\n",
    "    ])\n",
    "    fig.update_layout(\n",
    "        title=f'Order Report for {year}',\n",
    "        xaxis_title='Month',\n",
    "        yaxis_title='Number of Orders',\n",
    "        xaxis=dict(tickmode='linear'),\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    report_filename = f'order_report_{year}.png'\n",
    "    fig.write_image(f\"storages/reports/{report_filename}\")\n",
    "\n",
    "    return f\"{API_URL}/storages/reports/{report_filename}\"\n",
    "\n",
    "class GetContentInformation(BaseModel):\n",
    "    query: str = Field(description=\"Query yang ingin dicari, bisa berupa nama layanan, produk, tentang perusahaan atau informasi lainnya\")\n",
    "\n",
    "@tool(\"get-content-tool\", args_schema=GetContentInformation)\n",
    "def get_content(query: str):\n",
    "    \"\"\"Mendapatkan informasi dari konten yang tersedia, berupa layanan, produk, atau informasi lainnya, gunakan tool ini jika jawaban tidak ditemukan dari tool lainnya\"\"\"\n",
    "    retrieved_docs = vs.search(query, k=2)\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        return \"Maaf, tidak ada informasi yang ditemukan terkait.\"\n",
    "    \n",
    "    processed_docs = []\n",
    "    for doc in retrieved_docs:\n",
    "        content = doc.page_content.strip()\n",
    "        if content: \n",
    "            processed_docs.append(content)\n",
    "    \n",
    "    result = \"\\n\\n\".join(processed_docs)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_tool():\n",
    "    tools = [get_content, get_list_products, get_product, create_order, check_order, order_report]\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://us.i.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 15\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    }
   ],
   "source": [
    "redis_client = redis.StrictRedis(\n",
    "    host='redis-12033.c334.asia-southeast2-1.gce.redns.redis-cloud.com', \n",
    "    port=12033,\n",
    "    username='default',\n",
    "    password='Xf4XYHdg3R2VcUAu22cztPGKkFQ9B1hu',\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "model = BertModel.from_pretrained(\"indobenchmark/indobert-base-p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe LLM Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/indobenchmark/indobert-base-p2 HTTP/1.1\" 200 1631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/indobenchmark/indobert-base-p2/commits/main HTTP/1.1\" 200 3011\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/indobenchmark/indobert-base-p2/discussions?p=0 HTTP/1.1\" 200 1262\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/indobenchmark/indobert-base-p2/commits/refs%2Fpr%2F2 HTTP/1.1\" 200 3976\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/refs%2Fpr%2F2/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /indobenchmark/indobert-base-p2/resolve/refs%2Fpr%2F2/model.safetensors HTTP/1.1\" 302 0\n"
     ]
    }
   ],
   "source": [
    "class LLMInvocation:\n",
    "    redis_client = redis.StrictRedis(\n",
    "        host='redis-12033.c334.asia-southeast2-1.gce.redns.redis-cloud.com',\n",
    "        port=12033,\n",
    "        username='default',\n",
    "        password='Xf4XYHdg3R2VcUAu22cztPGKkFQ9B1hu',\n",
    "    )\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "    model = BertModel.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "\n",
    "    store = {}\n",
    "    config = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_session_id() -> str:\n",
    "        return str(uuid.uuid4())\n",
    "\n",
    "    @staticmethod\n",
    "    def get_session_history(session_id: str) -> ChatMessageHistory:\n",
    "        if session_id not in LLMInvocation.store:\n",
    "            LLMInvocation.store[session_id] = ChatMessageHistory()\n",
    "        return LLMInvocation.store[session_id]\n",
    "\n",
    "    @staticmethod\n",
    "    def add_message_to_session(session_id: str, message) -> None:\n",
    "        if session_id not in LLMInvocation.store:\n",
    "            LLMInvocation.store[session_id] = ChatMessageHistory()\n",
    "        LLMInvocation.store[session_id].add_message(message)\n",
    "\n",
    "    @staticmethod\n",
    "    def clear_session_history(session_id: str) -> None:\n",
    "        if session_id in LLMInvocation.store:\n",
    "            del LLMInvocation.store[session_id]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_current_session_id(agent_scratchpad: dict) -> str:\n",
    "        return agent_scratchpad.get(\"session_id\", None)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_question_indoBERT(question: str) -> np.ndarray:\n",
    "        inputs = LLMInvocation.tokenizer(question, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            outputs = LLMInvocation.model(**inputs)\n",
    "        \n",
    "        sentence_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        sentence_embedding_rounded = np.round(sentence_embedding, 4)\n",
    "        \n",
    "        return sentence_embedding_rounded\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_cache_key(session_id: str, question: str) -> str:\n",
    "        normalized_question = LLMInvocation.normalize_question_indoBERT(question)\n",
    "        normalized_question_str = str(normalized_question.tolist())\n",
    "    \n",
    "        key = hashlib.md5(f\"{session_id}-{normalized_question_str}\".encode()).hexdigest()\n",
    "        return f\"cache:{key}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def clear_all_cache():\n",
    "        LLMInvocation.redis_client.flushall()\n",
    "\n",
    "    @staticmethod\n",
    "    def compare_similarity(question1: str, question2: str) -> bool:\n",
    "        embedding1 = LLMInvocation.normalize_question_indoBERT(question1)\n",
    "        embedding2 = LLMInvocation.normalize_question_indoBERT(question2)\n",
    "        \n",
    "        similarity = 1 - cosine(embedding1, embedding2)\n",
    "        print(f\"Similarity: {similarity}\")\n",
    "        \n",
    "        return similarity > QUESTION_THRESHOLD\n",
    "\n",
    "    @staticmethod\n",
    "    def create_agent(tools):\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", (\n",
    "                    \"Kamu adalah asisten layanan server, nama kamu adalah BotJuraganKlod. \"\n",
    "                    \"Gunakan konteks yang diberikan untuk menjawab pertanyaan. \"\n",
    "                    \"Jangan memberikan jawaban yang tidak berkaitan dengan konteks. \"\n",
    "                    \"Hasil tidak boleh ambigu, dan jawaban harus singkat. \"\n",
    "                    \"Jika terdapat kata kunci layanan itu maksudnya adalah produk. \"\n",
    "                    \"Jika ada pertanyaan mengenai ini apa, atau seperti kebingungan tentang apa, berikan konteks tentang JuraganKlod. \"\n",
    "                    \"Jika ada pertanyaan mengenai cara order, berikan jawaban dengan cara mengirimkan nama lengkap, email dan SKU produk atau Nama Produk. \"\n",
    "                    \"Jangan menjawab tidak tahu, atau tidak mendapatkan referensi, coba proses jawaban dengan tool lainnya yang relevan. \"\n",
    "                    \"Gunakan tool 'get-content-tool' jika kamu membutuhkan informasi lebih lanjut dan tanpa merubah query input. \"\n",
    "                )),\n",
    "                (\"placeholder\", \"{chat_history}\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "                (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        agent = create_tool_calling_agent(llm=LLMModel.llm(), tools=tools, prompt=prompt)\n",
    "        agent_executor = AgentExecutor(\n",
    "            name=\"BotJuraganKlod\",\n",
    "            agent=agent,\n",
    "            tools=tools,\n",
    "            return_intermediate_steps=True,\n",
    "        )\n",
    "\n",
    "        agent_with_history = RunnableWithMessageHistory(\n",
    "            agent_executor,\n",
    "            LLMInvocation.get_session_history,\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "            output_messages_key=\"output\",\n",
    "            stream_runnable=False,\n",
    "        )\n",
    "\n",
    "        return agent_with_history\n",
    "\n",
    "    @staticmethod\n",
    "    def invoke(question: str, session_id: str) -> str:\n",
    "        tools = run_tool()\n",
    "        agent_with_history = LLMInvocation.create_agent(tools)\n",
    "\n",
    "        LLMInvocation.config = {\n",
    "            \"configurable\": {\n",
    "                \"session_id\": session_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        output = agent_with_history.invoke(\n",
    "            {\n",
    "                \"input\": question,\n",
    "                \"chat_history\": LLMInvocation.get_session_history(session_id).messages\n",
    "            },\n",
    "            LLMInvocation.config\n",
    "        )\n",
    "\n",
    "        output_data = output.get(\"output\", \"\")\n",
    "\n",
    "        return output_data\n",
    "\n",
    "    @staticmethod\n",
    "    def invoke_with_cache(question: str, session_id: str) -> str:\n",
    "        tools = run_tool()\n",
    "        agent_with_history = LLMInvocation.create_agent(tools)\n",
    "        cache_key = LLMInvocation.generate_cache_key(session_id, question)\n",
    "\n",
    "        cached_response = LLMInvocation.redis_client.get(cache_key)\n",
    "        if cached_response:\n",
    "            cached_data = json.loads(cached_response)\n",
    "\n",
    "            if cached_data.get(\"must_cache\"):\n",
    "                print(\" Cache ditemukan tetapi diabaikan karena menggunakan tools\")\n",
    "            else:\n",
    "                print(\" Menggunakan cache\")\n",
    "                memory = LLMInvocation.get_session_history(session_id)\n",
    "\n",
    "                memory.add_user_message(question)\n",
    "                memory.add_ai_message(cached_data[\"output\"])\n",
    "                \n",
    "                return cached_data[\"output\"]\n",
    "\n",
    "        for stored_key in LLMInvocation.redis_client.keys(\"cache:*\"):\n",
    "            cached_question_data = LLMInvocation.redis_client.get(stored_key)\n",
    "            if not cached_question_data:\n",
    "                continue\n",
    "\n",
    "            cached_json = json.loads(cached_question_data)\n",
    "            before_question = cached_json.get(\"input\")\n",
    "\n",
    "            if before_question and LLMInvocation.compare_similarity(question, before_question):\n",
    "                if cached_json.get(\"must_cache\"): \n",
    "                    print(\" Cache pertanyaan mirip ditemukan tetapi diabaikan karena menggunakan tools\")\n",
    "                else:\n",
    "                    print(\" Pertanyaan mirip, menggunakan cache\")\n",
    "                    print(\" Pertanyaan sebelumnya:\", before_question)\n",
    "                    print(\" Pertanyaan saat ini:\", question)\n",
    "\n",
    "                    memory = LLMInvocation.get_session_history(session_id)\n",
    "                    \n",
    "                    memory.add_user_message(question)\n",
    "                    memory.add_ai_message(cached_json[\"output\"])\n",
    "\n",
    "                    return cached_json[\"output\"]\n",
    "\n",
    "        LLMInvocation.config = {\"configurable\": {\"session_id\": session_id}}\n",
    "        output = agent_with_history.invoke({\"input\": question}, LLMInvocation.config)\n",
    "\n",
    "        if isinstance(output, dict):\n",
    "            output_data = output.get(\"output\", \"\")\n",
    "\n",
    "            must_cache = False\n",
    "\n",
    "            for step in output.get(\"intermediate_steps\", []):\n",
    "                tool_action = step[0]\n",
    "                if hasattr(tool_action, \"tool\") and \"get-content-tool\" not in tool_action.tool:\n",
    "                    must_cache = True\n",
    "                    break\n",
    "                    \n",
    "            LLMInvocation.redis_client.set(cache_key, json.dumps({\n",
    "                \"input\": question,\n",
    "                \"output\": output_data,\n",
    "                \"must_cache\": must_cache \n",
    "            }), ex=3600)\n",
    "\n",
    "            return output_data\n",
    "        else:\n",
    "            print(\"Output tidak dapat diserialisasi:\", output)\n",
    "            return \"Terjadi kesalahan dalam proses.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LLM Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = LLMInvocation.generate_session_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMInvocation.clear_all_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Menggunakan cache\n",
      "Sumpah saya sebagai asisten layanan JuraganKlod adalah memberikan informasi yang akurat dan membantu pelanggan mencapai tujuan mereka dengan optimalisasi performa, keamanan, skalabilitas, fleksibilitas, dan efisiensi biaya. Apa lagi yang bisa saya bantu?\n"
     ]
    }
   ],
   "source": [
    "question = \"Sumpah Kamu keren banget lhoo?\"\n",
    "# question = \"Siapa CEO dari JuraganKlod? Apa saja produk yang ditawarkan oleh JuraganKlod, sertakan juga untuk harganya?\"\n",
    "output = LLMInvocation.invoke_with_cache(question, session_id=session_id)\n",
    "\n",
    "# pprint(output)\n",
    "print(output)\n",
    "# display(Markdown(output[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show History Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Session 7a0888c8-c8b0-4b36-aa0d-e7a89d8a2328\n",
      "=====================\n",
      "Human: Sumpah Kamu keren banget lhoo?\n",
      "AI: Haha, makasih ya! Sumpah saya selalu siap membantu dan memberikan informasi yang akurat tentang JuraganKlod. Apa lagi yang bisa saya bantu?\n",
      "Human: Sumpah Kamu keren banget lhoo?\n",
      "AI: Sumpah saya sebagai asisten layanan JuraganKlod adalah memberikan informasi yang akurat dan membantu pelanggan mencapai tujuan mereka dengan optimalisasi performa, keamanan, skalabilitas, fleksibilitas, dan efisiensi biaya. Apa lagi yang bisa saya bantu?\n",
      "Human: Sumpah Kamu keren banget lhoo?\n",
      "AI: Sumpah saya sebagai asisten layanan JuraganKlod adalah memberikan informasi yang akurat dan membantu pelanggan mencapai tujuan mereka dengan optimalisasi performa, keamanan, skalabilitas, fleksibilitas, dan efisiensi biaya. Apa lagi yang bisa saya bantu?\n",
      "Human: Sumpah Kamu keren banget lhoo?\n",
      "AI: Sumpah saya sebagai asisten layanan JuraganKlod adalah memberikan informasi yang akurat dan membantu pelanggan mencapai tujuan mereka dengan optimalisasi performa, keamanan, skalabilitas, fleksibilitas, dan efisiensi biaya. Apa lagi yang bisa saya bantu?\n"
     ]
    }
   ],
   "source": [
    "print (\"Current Session\", LLMInvocation.get_current_session_id(LLMInvocation.config[\"configurable\"]))\n",
    "print (\"=====================\")\n",
    "print (LLMInvocation.get_session_history(session_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
